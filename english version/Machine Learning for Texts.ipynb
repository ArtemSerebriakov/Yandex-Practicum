{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project for WikiShop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikishop online store launches a new service. Now users can edit and supplement product descriptions like in wiki communities. That is, customers offer their edits and comment on the changes of others. The store needs a tool that will search for toxic comments and send them for moderation. \n",
    "\n",
    "Train the model to categorize comments into positive and negative. You have a dataset with markup on the toxicity of edits.\n",
    "\n",
    "We will evaluate the model as successful if the quality metric value *F1* will be at least 0.75. \n",
    "\n",
    "**Description of data**\n",
    "\n",
    "The data is in the file `toxic_comments.csv`. The *text* column in it contains the text of the comment, and *toxic* contains the target attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work plan:\n",
    "1. Study the general information from the dataframe.\n",
    "2. Check the balance of the classes.\n",
    "3. Perform lemmatization of the text.\n",
    "4. Create a TF-IDF matrix.\n",
    "5. Build several models and find the value of F1 metric for them on the training sample.\n",
    "6. Check the quality of the best models on the test sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a> <br>\n",
    "# Table of Contents  \n",
    "1. [Preparation](#1)     \n",
    "2. [Training](#2)\n",
    "3. [Conclusion](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## Preparation\n",
    "[Back to the top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"toxic_comments.csv\", sep=\",\", index_col=[0])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"df.head(10)\";\n",
       "                var nbb_formatted_code = \"df.head(10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are upper case words in the texts, let's bring them to lower case for better performance of future models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"df['text'] = df[\\\"text\\\"].str.lower()\";\n",
       "                var nbb_formatted_code = \"df[\\\"text\\\"] = df[\\\"text\\\"].str.lower()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"text\"] = df[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d'aww! he matches this background colour i'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man, i'm really not trying to edit war. it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nmore\\ni can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you, sir, are my hero. any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\ncongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>your vandalism to the matt shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation\\nwhy the edits made under my usern...      0\n",
       "1  d'aww! he matches this background colour i'm s...      0\n",
       "2  hey man, i'm really not trying to edit war. it...      0\n",
       "3  \"\\nmore\\ni can't make any real suggestions on ...      0\n",
       "4  you, sir, are my hero. any chance you remember...      0\n",
       "5  \"\\n\\ncongratulations from me as well, use the ...      0\n",
       "6       cocksucker before you piss around on my work      1\n",
       "7  your vandalism to the matt shirvington article...      0\n",
       "8  sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"df.head(10)\";\n",
       "                var nbb_formatted_code = \"df.head(10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the lemmatized text in a new column `lemm_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39min 58s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"%%time\\ndf['lemm_text'] = df['text'].apply(lambda text: \\\" \\\".join(token.lemma_ for token in nlp(text) if not (token.is_stop \\n                                                                                                     or token.is_punct\\n                                                                                                    or token.like_num)))\";\n",
       "                var nbb_formatted_code = \"%%time\\ndf['lemm_text'] = df['text'].apply(lambda text: \\\" \\\".join(token.lemma_ for token in nlp(text) if not (token.is_stop \\n                                                                                                     or token.is_punct\\n                                                                                                    or token.like_num)))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "df['lemm_text'] = df['text'].apply(lambda text: \" \".join(token.lemma_ for token in nlp(text) if not (token.is_stop \n",
    "                                                                                                     or token.is_punct\n",
    "                                                                                                    or token.like_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation \\n edit username hardcore metallic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d'aww! he matches this background colour i'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww match background colour seemingly stick ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man, i'm really not trying to edit war. it...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man try edit war guy constantly remove rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nmore\\ni can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n \\n real suggestion improvement wonder secti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you, sir, are my hero. any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  explanation\\nwhy the edits made under my usern...      0   \n",
       "1  d'aww! he matches this background colour i'm s...      0   \n",
       "2  hey man, i'm really not trying to edit war. it...      0   \n",
       "3  \"\\nmore\\ni can't make any real suggestions on ...      0   \n",
       "4  you, sir, are my hero. any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation \\n edit username hardcore metallic...  \n",
       "1  d'aww match background colour seemingly stick ...  \n",
       "2  hey man try edit war guy constantly remove rel...  \n",
       "3  \\n \\n real suggestion improvement wonder secti...  \n",
       "4                      sir hero chance remember page  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"df.head()\";\n",
       "                var nbb_formatted_code = \"df.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"df.to_csv(r\\\"df_processed_11.csv\\\", index=False, sep=\\\",\\\")\";\n",
       "                var nbb_formatted_code = \"df.to_csv(r\\\"df_processed_11.csv\\\", index=False, sep=\\\",\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.to_csv(r\"df_processed_11.csv\", index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation \\n edit username hardcore metallic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d'aww! he matches this background colour i'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww match background colour seemingly stick ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man, i'm really not trying to edit war. it...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man try edit war guy constantly remove rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nmore\\ni can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n \\n real suggestion improvement wonder secti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you, sir, are my hero. any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\ncongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n congratulation use tool   talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "      <td>1</td>\n",
       "      <td>cocksucker piss work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>your vandalism to the matt shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>vandalism matt shirvington article revert   ban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry word nonsense offensive intend write art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  explanation\\nwhy the edits made under my usern...      0   \n",
       "1  d'aww! he matches this background colour i'm s...      0   \n",
       "2  hey man, i'm really not trying to edit war. it...      0   \n",
       "3  \"\\nmore\\ni can't make any real suggestions on ...      0   \n",
       "4  you, sir, are my hero. any chance you remember...      0   \n",
       "5  \"\\n\\ncongratulations from me as well, use the ...      0   \n",
       "6       cocksucker before you piss around on my work      1   \n",
       "7  your vandalism to the matt shirvington article...      0   \n",
       "8  sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  alignment on this subject and which are contra...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation \\n edit username hardcore metallic...  \n",
       "1  d'aww match background colour seemingly stick ...  \n",
       "2  hey man try edit war guy constantly remove rel...  \n",
       "3  \\n \\n real suggestion improvement wonder secti...  \n",
       "4                      sir hero chance remember page  \n",
       "5                \\n\\n congratulation use tool   talk  \n",
       "6                               cocksucker piss work  \n",
       "7    vandalism matt shirvington article revert   ban  \n",
       "8  sorry word nonsense offensive intend write art...  \n",
       "9               alignment subject contrary dulithgow  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_processed_11.csv\", sep=\",\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>seems we both have some.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>here, here and here.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8583</th>\n",
       "      <td>what is it that you can do as well as others? ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8824</th>\n",
       "      <td>what is i 78.146.102.144</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10068</th>\n",
       "      <td>i might as well give up then.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151541</th>\n",
       "      <td>something must be done!</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152543</th>\n",
       "      <td>same for this 166.137.240.20</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153041</th>\n",
       "      <td>which is over 9000 over 9000 over 9000 over 90...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155467</th>\n",
       "      <td>if you have more to say, put</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158740</th>\n",
       "      <td>why don't you do it? 24.68.148.215</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic lemm_text\n",
       "627                              seems we both have some.      0       NaN\n",
       "2400                                 here, here and here.      0       NaN\n",
       "8583    what is it that you can do as well as others? ...      0       NaN\n",
       "8824                             what is i 78.146.102.144      0       NaN\n",
       "10068                       i might as well give up then.      0       NaN\n",
       "...                                                   ...    ...       ...\n",
       "151541                            something must be done!      0       NaN\n",
       "152543                       same for this 166.137.240.20      0       NaN\n",
       "153041  which is over 9000 over 9000 over 9000 over 90...      0       NaN\n",
       "155467                       if you have more to say, put      0       NaN\n",
       "158740                 why don't you do it? 24.68.148.215      0       NaN\n",
       "\n",
       "[96 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"lemm_text\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are rows with empty values in the `lemm_text` column, they are few, so we can ignore them when building models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "toxic        0\n",
       "lemm_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most frequently occurring words in the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist(df[\"lemm_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Samples', ylabel='Counts'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.plot(10, cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that verbs occur most often. It is also worth noting that there are no punctuation marks, numbers, and service words in the graph, which indicates that the text processing is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the source data into two samples: training(80%) and test(20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"toxic\"]\n",
    "features = df[\"lemm_text\"]\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=RANDOM_STATE, stratify=target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting samples have the following sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127356,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31840,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see by the number of rows in each sample that the separation has been done correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the relative frequencies of the classes in the target feature `toxic'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898333\n",
       "1    0.101667\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_frequency = df[\"toxic\"].value_counts(normalize=True)\n",
    "class_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_frequency.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is an imbalance of classes in the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк в target_train по классам: [114408  12948]\n",
      "Количество строк в target_test по классам: [28603  3237]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Количество строк в target_train по классам: {np.bincount(target_train)}\")\n",
    "print(f\"Количество строк в target_test по классам: {np.bincount(target_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the class imbalance in `toxic' remains the same in the samples obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use class weighting in model building, i.e. we will give objects of a rare class a higher weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a corpuses of texts for training and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = features_train.values\n",
    "corpus_test = features_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a matrix with the TF-IDF values of the obtained corpuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## Training\n",
    "[Back to the top](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build several models to predict the values of the target attribute `toxic`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"pipeline_lr = Pipeline(\\n    [\\n        (\\\"vect\\\", CountVectorizer(stop_words=stopwords)),\\n        (\\\"tfidf\\\", TfidfTransformer()),\\n        (\\n            \\\"lr\\\",\\n            LogisticRegression(random_state=RANDOM_STATE, solver=\\\"liblinear\\\"),\\n        ),\\n    ]\\n)\";\n",
       "                var nbb_formatted_code = \"pipeline_lr = Pipeline(\\n    [\\n        (\\\"vect\\\", CountVectorizer(stop_words=stopwords)),\\n        (\\\"tfidf\\\", TfidfTransformer()),\\n        (\\\"lr\\\", LogisticRegression(random_state=RANDOM_STATE, solver=\\\"liblinear\\\"),),\\n    ]\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_lr = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(stop_words=stopwords)),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\"lr\", LogisticRegression(random_state=RANDOM_STATE, solver=\"liblinear\"),),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"parameters_lr = {\\\"vect__ngram_range\\\": ((1, 1), (1, 2)), \\\"lr__C\\\": (1.5, 2.5)}\";\n",
       "                var nbb_formatted_code = \"parameters_lr = {\\\"vect__ngram_range\\\": ((1, 1), (1, 2)), \\\"lr__C\\\": (1.5, 2.5)}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters_lr = {\"vect__ngram_range\": ((1, 1), (1, 2)), \"lr__C\": (1.5, 2.5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr__C': 2.5, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"%%time\\ngrid_lr = GridSearchCV(pipeline_lr, parameters_lr, scoring=\\\"f1\\\", cv=5, n_jobs=-1)\\ngrid_lr.fit(corpus_train, target_train)\\ngrid_lr.best_params_\";\n",
       "                var nbb_formatted_code = \"%%time\\ngrid_lr = GridSearchCV(pipeline_lr, parameters_lr, scoring=\\\"f1\\\", cv=5, n_jobs=-1)\\ngrid_lr.fit(corpus_train, target_train)\\ngrid_lr.best_params_\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "grid_lr = GridSearchCV(pipeline_lr, parameters_lr, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "grid_lr.fit(corpus_train, target_train)\n",
    "grid_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 модели линейной регрессии на обучающей выборке: 0.7624890828199182\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"print(\\n    \\\"f1 \\u043c\\u043e\\u0434\\u0435\\u043b\\u0438 \\u043b\\u0438\\u043d\\u0435\\u0439\\u043d\\u043e\\u0439 \\u0440\\u0435\\u0433\\u0440\\u0435\\u0441\\u0441\\u0438\\u0438 \\u043d\\u0430 \\u043e\\u0431\\u0443\\u0447\\u0430\\u044e\\u0449\\u0435\\u0439 \\u0432\\u044b\\u0431\\u043e\\u0440\\u043a\\u0435:\\\", grid_lr.best_score_,\\n)\";\n",
       "                var nbb_formatted_code = \"print(\\n    \\\"f1 \\u043c\\u043e\\u0434\\u0435\\u043b\\u0438 \\u043b\\u0438\\u043d\\u0435\\u0439\\u043d\\u043e\\u0439 \\u0440\\u0435\\u0433\\u0440\\u0435\\u0441\\u0441\\u0438\\u0438 \\u043d\\u0430 \\u043e\\u0431\\u0443\\u0447\\u0430\\u044e\\u0449\\u0435\\u0439 \\u0432\\u044b\\u0431\\u043e\\u0440\\u043a\\u0435:\\\", grid_lr.best_score_,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\n",
    "    \"f1 модели линейной регрессии на обучающей выборке:\", grid_lr.best_score_,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's consider the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"pipeline_tr = Pipeline(\\n    [\\n        (\\\"vect\\\", CountVectorizer(stop_words=stopwords)),\\n        (\\\"tfidf\\\", TfidfTransformer()),\\n        (\\\"tr\\\", DecisionTreeClassifier(random_state=RANDOM_STATE),),\\n    ]\\n)\";\n",
       "                var nbb_formatted_code = \"pipeline_tr = Pipeline(\\n    [\\n        (\\\"vect\\\", CountVectorizer(stop_words=stopwords)),\\n        (\\\"tfidf\\\", TfidfTransformer()),\\n        (\\\"tr\\\", DecisionTreeClassifier(random_state=RANDOM_STATE),),\\n    ]\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_tr = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(stop_words=stopwords)),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\"tr\", DecisionTreeClassifier(random_state=RANDOM_STATE),),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"parameters_tr = {\\\"vect__ngram_range\\\": ((1, 1), (1, 2)), \\\"tr__max_depth\\\": range(1, 10, 1)}\";\n",
       "                var nbb_formatted_code = \"parameters_tr = {\\n    \\\"vect__ngram_range\\\": ((1, 1), (1, 2)),\\n    \\\"tr__max_depth\\\": range(1, 10, 1),\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters_tr = {\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2)),\n",
    "    \"tr__max_depth\": range(1, 10, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tr__max_depth': 9, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"%%time\\ngrid_tr = GridSearchCV(pipeline_tr, parameters_tr, scoring=\\\"f1\\\", cv=5, n_jobs=-1)\\ngrid_tr.fit(corpus_train, target_train)\\ngrid_tr.best_params_\";\n",
       "                var nbb_formatted_code = \"%%time\\ngrid_tr = GridSearchCV(pipeline_tr, parameters_tr, scoring=\\\"f1\\\", cv=5, n_jobs=-1)\\ngrid_tr.fit(corpus_train, target_train)\\ngrid_tr.best_params_\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "grid_tr = GridSearchCV(pipeline_tr, parameters_tr, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "grid_tr.fit(corpus_train, target_train)\n",
    "grid_tr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 модели дерева решений на обучающей выборке: 0.5984427749050161\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"print(\\n    \\\"f1 \\u043c\\u043e\\u0434\\u0435\\u043b\\u0438 \\u0434\\u0435\\u0440\\u0435\\u0432\\u0430 \\u0440\\u0435\\u0448\\u0435\\u043d\\u0438\\u0439 \\u043d\\u0430 \\u043e\\u0431\\u0443\\u0447\\u0430\\u044e\\u0449\\u0435\\u0439 \\u0432\\u044b\\u0431\\u043e\\u0440\\u043a\\u0435:\\\", grid_tr.best_score_,\\n)\";\n",
       "                var nbb_formatted_code = \"print(\\n    \\\"f1 \\u043c\\u043e\\u0434\\u0435\\u043b\\u0438 \\u0434\\u0435\\u0440\\u0435\\u0432\\u0430 \\u0440\\u0435\\u0448\\u0435\\u043d\\u0438\\u0439 \\u043d\\u0430 \\u043e\\u0431\\u0443\\u0447\\u0430\\u044e\\u0449\\u0435\\u0439 \\u0432\\u044b\\u0431\\u043e\\u0440\\u043a\\u0435:\\\", grid_tr.best_score_,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\n",
    "    \"f1 модели дерева решений на обучающей выборке:\", grid_tr.best_score_,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model of the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"pipeline_rf = Pipeline(\\n    [\\n        (\\\"vect\\\", CountVectorizer(stop_words=stopwords)),\\n        (\\\"tfidf\\\", TfidfTransformer()),\\n        (\\\"rf\\\", RandomForestClassifier(random_state=RANDOM_STATE)),\\n    ]\\n)\";\n",
       "                var nbb_formatted_code = \"pipeline_rf = Pipeline(\\n    [\\n        (\\\"vect\\\", CountVectorizer(stop_words=stopwords)),\\n        (\\\"tfidf\\\", TfidfTransformer()),\\n        (\\\"rf\\\", RandomForestClassifier(random_state=RANDOM_STATE)),\\n    ]\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_rf = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(stop_words=stopwords)),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\"rf\", RandomForestClassifier(random_state=RANDOM_STATE)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"parameters_rf = {\\n    \\\"vect__ngram_range\\\": ((1, 1), (1, 2)),\\n    \\\"rf__n_estimators\\\": range(10, 31, 5),\\n}\";\n",
       "                var nbb_formatted_code = \"parameters_rf = {\\n    \\\"vect__ngram_range\\\": ((1, 1), (1, 2)),\\n    \\\"rf__n_estimators\\\": range(10, 31, 5),\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters_rf = {\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2)),\n",
    "    \"rf__n_estimators\": range(10, 31, 5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 33min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rf__n_estimators': 25, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"%%time\\ngrid_rf = GridSearchCV(pipeline_rf, parameters_rf, scoring=\\\"f1\\\", cv=3)\\ngrid_rf.fit(corpus_train, target_train)\\ngrid_rf.best_params_\";\n",
       "                var nbb_formatted_code = \"%%time\\ngrid_rf = GridSearchCV(pipeline_rf, parameters_rf, scoring=\\\"f1\\\", cv=3)\\ngrid_rf.fit(corpus_train, target_train)\\ngrid_rf.best_params_\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "grid_rf = GridSearchCV(pipeline_rf, parameters_rf, scoring=\"f1\", cv=3)\n",
    "grid_rf.fit(corpus_train, target_train)\n",
    "grid_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 модели случайного леса на обучающей выборке: 0.7172610034737178\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"print(\\n    \\\"f1 \\u043c\\u043e\\u0434\\u0435\\u043b\\u0438 \\u0441\\u043b\\u0443\\u0447\\u0430\\u0439\\u043d\\u043e\\u0433\\u043e \\u043b\\u0435\\u0441\\u0430 \\u043d\\u0430 \\u043e\\u0431\\u0443\\u0447\\u0430\\u044e\\u0449\\u0435\\u0439 \\u0432\\u044b\\u0431\\u043e\\u0440\\u043a\\u0435:\\\", grid_rf.best_score_,\\n)\";\n",
       "                var nbb_formatted_code = \"print(\\n    \\\"f1 \\u043c\\u043e\\u0434\\u0435\\u043b\\u0438 \\u0441\\u043b\\u0443\\u0447\\u0430\\u0439\\u043d\\u043e\\u0433\\u043e \\u043b\\u0435\\u0441\\u0430 \\u043d\\u0430 \\u043e\\u0431\\u0443\\u0447\\u0430\\u044e\\u0449\\u0435\\u0439 \\u0432\\u044b\\u0431\\u043e\\u0440\\u043a\\u0435:\\\", grid_rf.best_score_,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\n",
    "    \"f1 модели случайного леса на обучающей выборке:\", grid_rf.best_score_,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will build a gradient boosting model using the CatBoost and LightGBM libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 67;\n",
       "                var nbb_unformatted_code = \"pipeline_CBR = Pipeline(\\n    [\\n        (\\\"vect\\\", CountVectorizer(stop_words=stopwords)),\\n        (\\\"tfidf\\\", TfidfTransformer()),\\n        (\\n            \\\"CBR\\\",\\n            CatBoostClassifier(\\n                random_state=RANDOM_STATE,\\n                loss_function=\\\"Logloss\\\",\\n                eval_metric=\\\"TotalF1\\\",\\n                verbose=250,\\n            ),\\n        ),\\n    ]\\n)\";\n",
       "                var nbb_formatted_code = \"pipeline_CBR = Pipeline(\\n    [\\n        (\\\"vect\\\", CountVectorizer(stop_words=stopwords)),\\n        (\\\"tfidf\\\", TfidfTransformer()),\\n        (\\n            \\\"CBR\\\",\\n            CatBoostClassifier(\\n                random_state=RANDOM_STATE,\\n                loss_function=\\\"Logloss\\\",\\n                eval_metric=\\\"TotalF1\\\",\\n                verbose=250,\\n            ),\\n        ),\\n    ]\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_CBR = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(stop_words=stopwords)),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\n",
    "            \"CBR\",\n",
    "            CatBoostClassifier(\n",
    "                random_state=RANDOM_STATE,\n",
    "                loss_function=\"Logloss\",\n",
    "                eval_metric=\"TotalF1\",\n",
    "                verbose=250,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 70;\n",
       "                var nbb_unformatted_code = \"parameters_CBR = {\\n    #\\\"vect__ngram_range\\\": ((1, 1)),\\n    \\\"CBR__depth\\\": [3, 4],\\n    \\\"CBR__learning_rate\\\": [0.3, 0.5],\\n    \\\"CBR__iterations\\\": [500],\\n}\";\n",
       "                var nbb_formatted_code = \"parameters_CBR = {\\n    # \\\"vect__ngram_range\\\": ((1, 1)),\\n    \\\"CBR__depth\\\": [3, 4],\\n    \\\"CBR__learning_rate\\\": [0.3, 0.5],\\n    \\\"CBR__iterations\\\": [500],\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters_CBR = {\n",
    "    \"CBR__depth\": [3, 4],\n",
    "    \"CBR__learning_rate\": [0.3, 0.5],\n",
    "    \"CBR__iterations\": [500],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9005317\ttotal: 252ms\tremaining: 2m 5s\n",
      "250:\tlearn: 0.9545587\ttotal: 1m 40s\tremaining: 1m 39s\n",
      "499:\tlearn: 0.9601336\ttotal: 3m 58s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8974554\ttotal: 386ms\tremaining: 3m 12s\n",
      "250:\tlearn: 0.9555858\ttotal: 2m 6s\tremaining: 2m 5s\n",
      "499:\tlearn: 0.9617632\ttotal: 3m 55s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8949568\ttotal: 374ms\tremaining: 3m 6s\n",
      "250:\tlearn: 0.9557340\ttotal: 2m 3s\tremaining: 2m 2s\n",
      "499:\tlearn: 0.9612428\ttotal: 3m 56s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9005317\ttotal: 364ms\tremaining: 3m 1s\n",
      "250:\tlearn: 0.9597721\ttotal: 2m 2s\tremaining: 2m 1s\n",
      "499:\tlearn: 0.9667704\ttotal: 3m 54s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8974554\ttotal: 1.48s\tremaining: 12m 18s\n",
      "250:\tlearn: 0.9610128\ttotal: 1m 59s\tremaining: 1m 58s\n",
      "499:\tlearn: 0.9670856\ttotal: 3m 51s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8949568\ttotal: 355ms\tremaining: 2m 57s\n",
      "250:\tlearn: 0.9607363\ttotal: 1m 59s\tremaining: 1m 58s\n",
      "499:\tlearn: 0.9673826\ttotal: 3m 50s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9005412\ttotal: 536ms\tremaining: 4m 27s\n",
      "250:\tlearn: 0.9569901\ttotal: 2m 47s\tremaining: 2m 45s\n",
      "499:\tlearn: 0.9644541\ttotal: 5m 14s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8974554\ttotal: 470ms\tremaining: 3m 54s\n",
      "250:\tlearn: 0.9579315\ttotal: 2m 38s\tremaining: 2m 36s\n",
      "499:\tlearn: 0.9654606\ttotal: 5m 14s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9061052\ttotal: 510ms\tremaining: 4m 14s\n",
      "250:\tlearn: 0.9580413\ttotal: 2m 41s\tremaining: 2m 40s\n",
      "499:\tlearn: 0.9649598\ttotal: 5m 19s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9005412\ttotal: 476ms\tremaining: 3m 57s\n",
      "250:\tlearn: 0.9639298\ttotal: 2m 35s\tremaining: 2m 34s\n",
      "499:\tlearn: 0.9681408\ttotal: 5m 9s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8974554\ttotal: 547ms\tremaining: 4m 32s\n",
      "250:\tlearn: 0.9648217\ttotal: 2m 34s\tremaining: 2m 33s\n",
      "499:\tlearn: 0.9683831\ttotal: 5m 18s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9061052\ttotal: 511ms\tremaining: 4m 14s\n",
      "250:\tlearn: 0.9641782\ttotal: 2m 46s\tremaining: 2m 44s\n",
      "499:\tlearn: 0.9685349\ttotal: 5m 27s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8971960\ttotal: 610ms\tremaining: 5m 4s\n",
      "250:\tlearn: 0.9597867\ttotal: 2m 24s\tremaining: 2m 23s\n",
      "499:\tlearn: 0.9653721\ttotal: 4m 44s\tremaining: 0us\n",
      "Wall time: 1h 3min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CBR__depth': 3, 'CBR__iterations': 500, 'CBR__learning_rate': 0.5}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 71;\n",
       "                var nbb_unformatted_code = \"%%time\\ngrid_CBR = GridSearchCV(pipeline_CBR, parameters_CBR, scoring=\\\"f1\\\", cv=3)\\ngrid_CBR.fit(corpus_train, target_train)\\ngrid_CBR.best_params_\";\n",
       "                var nbb_formatted_code = \"%%time\\ngrid_CBR = GridSearchCV(pipeline_CBR, parameters_CBR, scoring=\\\"f1\\\", cv=3)\\ngrid_CBR.fit(corpus_train, target_train)\\ngrid_CBR.best_params_\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "grid_CBR = GridSearchCV(pipeline_CBR, parameters_CBR, scoring=\"f1\", cv=3)\n",
    "grid_CBR.fit(corpus_train, target_train)\n",
    "grid_CBR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 модели CatBoostClassifier на обучающей выборке: 0.7578957744512946\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 72;\n",
       "                var nbb_unformatted_code = \"print(\\n    \\\"f1 \\u043c\\u043e\\u0434\\u0435\\u043b\\u0438 CatBoostClassifier \\u043d\\u0430 \\u043e\\u0431\\u0443\\u0447\\u0430\\u044e\\u0449\\u0435\\u0439 \\u0432\\u044b\\u0431\\u043e\\u0440\\u043a\\u0435:\\\",\\n    grid_CBR.best_score_,\\n)\";\n",
       "                var nbb_formatted_code = \"print(\\n    \\\"f1 \\u043c\\u043e\\u0434\\u0435\\u043b\\u0438 CatBoostClassifier \\u043d\\u0430 \\u043e\\u0431\\u0443\\u0447\\u0430\\u044e\\u0449\\u0435\\u0439 \\u0432\\u044b\\u0431\\u043e\\u0440\\u043a\\u0435:\\\", grid_CBR.best_score_,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\n",
    "    \"f1 модели CatBoostClassifier на обучающей выборке:\", grid_CBR.best_score_,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 75;\n",
       "                var nbb_unformatted_code = \"pipeline_lgb = Pipeline(\\n    [\\n        (\\\"vect\\\", CountVectorizer(stop_words=stopwords)),\\n        (\\\"tfidf\\\", TfidfTransformer()),\\n        (\\\"lgb\\\", lgb.LGBMClassifier(verbosity=-1)),\\n    ]\\n)\";\n",
       "                var nbb_formatted_code = \"pipeline_lgb = Pipeline(\\n    [\\n        (\\\"vect\\\", CountVectorizer(stop_words=stopwords)),\\n        (\\\"tfidf\\\", TfidfTransformer()),\\n        (\\\"lgb\\\", lgb.LGBMClassifier(verbosity=-1)),\\n    ]\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_lgb = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(stop_words=stopwords)),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\"lgb\", lgb.LGBMClassifier(verbosity=-1)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 74;\n",
       "                var nbb_unformatted_code = \"parameters_lgb = {\\n    \\\"vect__ngram_range\\\": ((1, 1), (1, 2)),\\n    'lgb__max_depth' : [3, 4],\\n    'lgb__learning_rate' : [0.3, 0.5],\\n    'lgb__n_estimators'    : [500]\\n}\";\n",
       "                var nbb_formatted_code = \"parameters_lgb = {\\n    \\\"vect__ngram_range\\\": ((1, 1), (1, 2)),\\n    \\\"lgb__max_depth\\\": [3, 4],\\n    \\\"lgb__learning_rate\\\": [0.3, 0.5],\\n    \\\"lgb__n_estimators\\\": [500],\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters_lgb = {\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2)),\n",
    "    \"lgb__max_depth\": [3, 4],\n",
    "    \"lgb__learning_rate\": [0.3, 0.5],\n",
    "    \"lgb__n_estimators\": [500],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\Sereb\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lgb__learning_rate': 0.3,\n",
       " 'lgb__max_depth': 3,\n",
       " 'lgb__n_estimators': 500,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 76;\n",
       "                var nbb_unformatted_code = \"%%time\\ngrid_lgb = GridSearchCV(pipeline_lgb, parameters_lgb, scoring=\\\"f1\\\", cv=3)\\ngrid_lgb.fit(corpus_train, target_train)\\ngrid_lgb.best_params_\";\n",
       "                var nbb_formatted_code = \"%%time\\ngrid_lgb = GridSearchCV(pipeline_lgb, parameters_lgb, scoring=\\\"f1\\\", cv=3)\\ngrid_lgb.fit(corpus_train, target_train)\\ngrid_lgb.best_params_\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "grid_lgb = GridSearchCV(pipeline_lgb, parameters_lgb, scoring=\"f1\", cv=3)\n",
    "grid_lgb.fit(corpus_train, target_train)\n",
    "grid_lgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 модели LGBMRegressor на обучающей выборке: 0.7718777660732652\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 77;\n",
       "                var nbb_unformatted_code = \"print(\\n    \\\"f1 \\u043c\\u043e\\u0434\\u0435\\u043b\\u0438 LGBMRegressor \\u043d\\u0430 \\u043e\\u0431\\u0443\\u0447\\u0430\\u044e\\u0449\\u0435\\u0439 \\u0432\\u044b\\u0431\\u043e\\u0440\\u043a\\u0435:\\\", grid_lgb.best_score_,\\n)\";\n",
       "                var nbb_formatted_code = \"print(\\n    \\\"f1 \\u043c\\u043e\\u0434\\u0435\\u043b\\u0438 LGBMRegressor \\u043d\\u0430 \\u043e\\u0431\\u0443\\u0447\\u0430\\u044e\\u0449\\u0435\\u0439 \\u0432\\u044b\\u0431\\u043e\\u0440\\u043a\\u0435:\\\", grid_lgb.best_score_,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\n",
    "    \"f1 модели LGBMRegressor на обучающей выборке:\", grid_lgb.best_score_,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## Conclusion\n",
    "[Back to the top](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the obtained values of the f1 metric for different models, it is evident that the LGBMRegressor gradient-boosting model showed the best result. Let's check its quality on the test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7730605285592498"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 79;\n",
       "                var nbb_unformatted_code = \"pred = grid_lgb.best_estimator_.predict(corpus_test)\\nf1_score(pred, target_test)\";\n",
       "                var nbb_formatted_code = \"pred = grid_lgb.best_estimator_.predict(corpus_test)\\nf1_score(pred, target_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = grid_lgb.best_estimator_.predict(corpus_test)\n",
    "f1_score(pred, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the LGBMClassifier model shows close values of the f1 metric on the training and test samples. The desired accuracy of the model on the test sample has been achieved (f1=0.77 > 0.75)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, the following models were built and trained on a markup dataset of comment toxicity using the TF-IDF matrix: LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, CatBoostClassifier, and LGBMClassifier. These were used to make predictions about the tonality of the comments. Based on the F1 metric values, the one with the best prediction quality was selected. It was the gradient boosting model LGBMClassifier with F1 value equal to 0.77."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
